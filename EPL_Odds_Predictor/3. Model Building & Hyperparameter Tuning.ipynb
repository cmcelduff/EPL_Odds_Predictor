{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f4cd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation_functions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn import linear_model, tree, discriminant_analysis, naive_bayes, ensemble, gaussian_process\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d565092",
   "metadata": {},
   "source": [
    "## 3. Model Building & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56599a76",
   "metadata": {},
   "source": [
    "This section will look to cover 3 main points:\n",
    "1. Choosing which Machine Learning algorithm to use from a variety of choices\n",
    "2. Hyperparameter Tuning\n",
    "3. Overfitting/Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c467f42",
   "metadata": {},
   "source": [
    "### Choosing an Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b10a28",
   "metadata": {},
   "source": [
    "The best way to choose an algorithm is to test all of them and decide after reviewing their metrics. <br>\n",
    "To do this, it is necessary to define a function that iterates over a number of algorithms and gives us an indication of which algorithms are suited to this dataset and exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65a2269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all games feature DataFrame\n",
      "Creating stats feature DataFrame\n",
      "Creating odds feature DataFrame\n",
      "Creating market values feature DataFrame\n",
      "Filling NAs\n",
      "Merging stats, odds and market values into one features DataFrame\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "features = create_feature_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32865878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>gameId</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>season</th>\n",
       "      <th>f_homeWinPc38Home</th>\n",
       "      <th>f_homeWinPc5Home</th>\n",
       "      <th>f_awayWinPc38Home</th>\n",
       "      <th>f_awayWinPc5Home</th>\n",
       "      <th>f_eloForHome</th>\n",
       "      <th>f_eloAgainstHome</th>\n",
       "      <th>f_wtEloGoalsForHome</th>\n",
       "      <th>f_wtEloGoalsAgainstHome</th>\n",
       "      <th>f_cornersAgainstHome</th>\n",
       "      <th>f_cornersForHome</th>\n",
       "      <th>f_freesAgainstHome</th>\n",
       "      <th>f_freesForHome</th>\n",
       "      <th>f_goalsAgainstHome</th>\n",
       "      <th>f_goalsForHome</th>\n",
       "      <th>f_halfTimeGoalsAgainstHome</th>\n",
       "      <th>f_halfTimeGoalsForHome</th>\n",
       "      <th>f_redsAgainstHome</th>\n",
       "      <th>f_redsForHome</th>\n",
       "      <th>f_shotsAgainstHome</th>\n",
       "      <th>f_shotsForHome</th>\n",
       "      <th>f_shotsOnTargetAgainstHome</th>\n",
       "      <th>f_shotsOnTargetForHome</th>\n",
       "      <th>f_yellowsAgainstHome</th>\n",
       "      <th>f_yellowsForHome</th>\n",
       "      <th>f_avAsianHandicapOddsAgainstHome</th>\n",
       "      <th>f_avAsianHandicapOddsForHome</th>\n",
       "      <th>f_avgreaterthan2.5Home</th>\n",
       "      <th>f_avlessthan2.5Home</th>\n",
       "      <th>f_sizeOfHandicapHome</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>f_homeWinPc38Away</th>\n",
       "      <th>f_homeWinPc5Away</th>\n",
       "      <th>f_awayWinPc38Away</th>\n",
       "      <th>f_awayWinPc5Away</th>\n",
       "      <th>f_eloForAway</th>\n",
       "      <th>f_eloAgainstAway</th>\n",
       "      <th>f_wtEloGoalsForAway</th>\n",
       "      <th>f_wtEloGoalsAgainstAway</th>\n",
       "      <th>f_cornersAgainstAway</th>\n",
       "      <th>f_cornersForAway</th>\n",
       "      <th>f_freesAgainstAway</th>\n",
       "      <th>f_freesForAway</th>\n",
       "      <th>f_goalsAgainstAway</th>\n",
       "      <th>f_goalsForAway</th>\n",
       "      <th>f_halfTimeGoalsAgainstAway</th>\n",
       "      <th>f_halfTimeGoalsForAway</th>\n",
       "      <th>f_redsAgainstAway</th>\n",
       "      <th>f_redsForAway</th>\n",
       "      <th>f_shotsAgainstAway</th>\n",
       "      <th>f_shotsForAway</th>\n",
       "      <th>f_shotsOnTargetAgainstAway</th>\n",
       "      <th>f_shotsOnTargetForAway</th>\n",
       "      <th>f_yellowsAgainstAway</th>\n",
       "      <th>f_yellowsForAway</th>\n",
       "      <th>f_avAsianHandicapOddsAgainstAway</th>\n",
       "      <th>f_avAsianHandicapOddsForAway</th>\n",
       "      <th>f_avgreaterthan2.5Away</th>\n",
       "      <th>f_avlessthan2.5Away</th>\n",
       "      <th>f_sizeOfHandicapAway</th>\n",
       "      <th>f_attMktH%</th>\n",
       "      <th>f_attMktA%</th>\n",
       "      <th>f_midMktH%</th>\n",
       "      <th>f_midMktA%</th>\n",
       "      <th>f_defMktH%</th>\n",
       "      <th>f_defMktA%</th>\n",
       "      <th>f_gkMktH%</th>\n",
       "      <th>f_gkMktA%</th>\n",
       "      <th>f_totalMktH%</th>\n",
       "      <th>f_totalMktA%</th>\n",
       "      <th>result</th>\n",
       "      <th>f_awayOdds</th>\n",
       "      <th>f_drawOdds</th>\n",
       "      <th>f_homeOdds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2005-08-23</td>\n",
       "      <td>21</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>0506</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1478.687038</td>\n",
       "      <td>1492.866048</td>\n",
       "      <td>1.061763</td>\n",
       "      <td>1.260223</td>\n",
       "      <td>4.979592</td>\n",
       "      <td>7.530612</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.938776</td>\n",
       "      <td>1.020408</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938776</td>\n",
       "      <td>8.020408</td>\n",
       "      <td>6.489796</td>\n",
       "      <td>2.979592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.510204</td>\n",
       "      <td>1.909000</td>\n",
       "      <td>1.945500</td>\n",
       "      <td>2.051000</td>\n",
       "      <td>1.673500</td>\n",
       "      <td>-0.137500</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1492.866048</td>\n",
       "      <td>1478.687038</td>\n",
       "      <td>1.129940</td>\n",
       "      <td>1.279873</td>\n",
       "      <td>2.551020</td>\n",
       "      <td>5.510204</td>\n",
       "      <td>13.551020</td>\n",
       "      <td>13.428571</td>\n",
       "      <td>1.020408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>17.020408</td>\n",
       "      <td>8.081633</td>\n",
       "      <td>7.510204</td>\n",
       "      <td>2.510204</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.489796</td>\n",
       "      <td>1.939500</td>\n",
       "      <td>1.909500</td>\n",
       "      <td>2.003500</td>\n",
       "      <td>1.715500</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>5.132983</td>\n",
       "      <td>5.260851</td>\n",
       "      <td>3.341048</td>\n",
       "      <td>4.289788</td>\n",
       "      <td>3.502318</td>\n",
       "      <td>4.168935</td>\n",
       "      <td>2.332815</td>\n",
       "      <td>3.216457</td>\n",
       "      <td>3.934396</td>\n",
       "      <td>4.522205</td>\n",
       "      <td>away</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2005-08-23</td>\n",
       "      <td>22</td>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>0506</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1405.968416</td>\n",
       "      <td>1489.229314</td>\n",
       "      <td>1.147101</td>\n",
       "      <td>1.503051</td>\n",
       "      <td>2.510204</td>\n",
       "      <td>4.959184</td>\n",
       "      <td>21.979592</td>\n",
       "      <td>16.061224</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.448980</td>\n",
       "      <td>10.489796</td>\n",
       "      <td>3.959184</td>\n",
       "      <td>4.448980</td>\n",
       "      <td>3.020408</td>\n",
       "      <td>1.530612</td>\n",
       "      <td>1.896500</td>\n",
       "      <td>1.969000</td>\n",
       "      <td>2.004000</td>\n",
       "      <td>1.700500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1489.229314</td>\n",
       "      <td>1405.968416</td>\n",
       "      <td>1.175160</td>\n",
       "      <td>1.263229</td>\n",
       "      <td>9.530612</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.469388</td>\n",
       "      <td>17.571429</td>\n",
       "      <td>1.489796</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.551020</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.061224</td>\n",
       "      <td>2.510204</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>1.856500</td>\n",
       "      <td>1.977000</td>\n",
       "      <td>1.850500</td>\n",
       "      <td>1.848500</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>3.738614</td>\n",
       "      <td>3.878659</td>\n",
       "      <td>4.494368</td>\n",
       "      <td>4.954673</td>\n",
       "      <td>2.884262</td>\n",
       "      <td>4.065926</td>\n",
       "      <td>3.746642</td>\n",
       "      <td>5.372543</td>\n",
       "      <td>3.743410</td>\n",
       "      <td>4.365456</td>\n",
       "      <td>draw</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2005-08-23</td>\n",
       "      <td>23</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>0506</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1277.888970</td>\n",
       "      <td>1552.291880</td>\n",
       "      <td>0.650176</td>\n",
       "      <td>1.543716</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.408163</td>\n",
       "      <td>17.551020</td>\n",
       "      <td>1.979592</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>14.510204</td>\n",
       "      <td>6.897959</td>\n",
       "      <td>5.020408</td>\n",
       "      <td>3.918367</td>\n",
       "      <td>1.020408</td>\n",
       "      <td>2.510204</td>\n",
       "      <td>1.852000</td>\n",
       "      <td>1.991500</td>\n",
       "      <td>1.853500</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1552.291880</td>\n",
       "      <td>1277.888970</td>\n",
       "      <td>1.288750</td>\n",
       "      <td>1.287367</td>\n",
       "      <td>7.530612</td>\n",
       "      <td>3.510204</td>\n",
       "      <td>8.959184</td>\n",
       "      <td>12.489796</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>1.020408</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.959184</td>\n",
       "      <td>11.938776</td>\n",
       "      <td>2.489796</td>\n",
       "      <td>6.979592</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.489796</td>\n",
       "      <td>1.815000</td>\n",
       "      <td>2.039500</td>\n",
       "      <td>2.006000</td>\n",
       "      <td>1.709500</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.706318</td>\n",
       "      <td>3.750792</td>\n",
       "      <td>1.476812</td>\n",
       "      <td>1.070209</td>\n",
       "      <td>2.634096</td>\n",
       "      <td>4.455890</td>\n",
       "      <td>0.777605</td>\n",
       "      <td>4.913050</td>\n",
       "      <td>1.499427</td>\n",
       "      <td>3.151477</td>\n",
       "      <td>away</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2005-08-24</td>\n",
       "      <td>24</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0506</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1729.086068</td>\n",
       "      <td>1481.943781</td>\n",
       "      <td>2.099593</td>\n",
       "      <td>0.921523</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.489796</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.061224</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>11.938776</td>\n",
       "      <td>3.551020</td>\n",
       "      <td>7.408163</td>\n",
       "      <td>1.510204</td>\n",
       "      <td>1.530612</td>\n",
       "      <td>1.945500</td>\n",
       "      <td>1.909000</td>\n",
       "      <td>1.876000</td>\n",
       "      <td>1.828500</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1481.943781</td>\n",
       "      <td>1729.086068</td>\n",
       "      <td>1.170928</td>\n",
       "      <td>1.323440</td>\n",
       "      <td>7.020408</td>\n",
       "      <td>3.448980</td>\n",
       "      <td>19.632653</td>\n",
       "      <td>13.020408</td>\n",
       "      <td>1.020408</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.591837</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>6.551020</td>\n",
       "      <td>5.469388</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.510204</td>\n",
       "      <td>2.061000</td>\n",
       "      <td>1.799000</td>\n",
       "      <td>2.023500</td>\n",
       "      <td>1.684500</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>10.807882</td>\n",
       "      <td>0.785474</td>\n",
       "      <td>8.064289</td>\n",
       "      <td>4.161925</td>\n",
       "      <td>9.116327</td>\n",
       "      <td>3.583254</td>\n",
       "      <td>3.661813</td>\n",
       "      <td>5.337198</td>\n",
       "      <td>9.031622</td>\n",
       "      <td>2.924604</td>\n",
       "      <td>home</td>\n",
       "      <td>13.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2005-08-24</td>\n",
       "      <td>25</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>0506</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1496.457214</td>\n",
       "      <td>1535.410612</td>\n",
       "      <td>1.248951</td>\n",
       "      <td>1.308457</td>\n",
       "      <td>1.489796</td>\n",
       "      <td>7.020408</td>\n",
       "      <td>12.530612</td>\n",
       "      <td>20.122449</td>\n",
       "      <td>1.979592</td>\n",
       "      <td>1.510204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>10.448980</td>\n",
       "      <td>13.551020</td>\n",
       "      <td>4.489796</td>\n",
       "      <td>7.040816</td>\n",
       "      <td>1.020408</td>\n",
       "      <td>1.510204</td>\n",
       "      <td>1.803500</td>\n",
       "      <td>2.056500</td>\n",
       "      <td>2.014500</td>\n",
       "      <td>1.693500</td>\n",
       "      <td>-0.275000</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1535.410612</td>\n",
       "      <td>1496.457214</td>\n",
       "      <td>1.274824</td>\n",
       "      <td>1.393005</td>\n",
       "      <td>6.489796</td>\n",
       "      <td>3.530612</td>\n",
       "      <td>11.469388</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.510204</td>\n",
       "      <td>14.571429</td>\n",
       "      <td>4.959184</td>\n",
       "      <td>7.020408</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>2.510204</td>\n",
       "      <td>1.914000</td>\n",
       "      <td>1.935000</td>\n",
       "      <td>1.976500</td>\n",
       "      <td>1.733500</td>\n",
       "      <td>-0.387500</td>\n",
       "      <td>1.583126</td>\n",
       "      <td>5.553120</td>\n",
       "      <td>3.477861</td>\n",
       "      <td>6.881561</td>\n",
       "      <td>4.010007</td>\n",
       "      <td>5.537488</td>\n",
       "      <td>2.297469</td>\n",
       "      <td>5.973420</td>\n",
       "      <td>2.916354</td>\n",
       "      <td>6.001831</td>\n",
       "      <td>draw</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>2018-08-25</td>\n",
       "      <td>4950</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>1819</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1549.801937</td>\n",
       "      <td>1567.656994</td>\n",
       "      <td>1.261521</td>\n",
       "      <td>1.720533</td>\n",
       "      <td>5.380406</td>\n",
       "      <td>5.765467</td>\n",
       "      <td>11.482014</td>\n",
       "      <td>9.224256</td>\n",
       "      <td>1.591704</td>\n",
       "      <td>1.359998</td>\n",
       "      <td>0.704842</td>\n",
       "      <td>0.500421</td>\n",
       "      <td>0.023102</td>\n",
       "      <td>0.024295</td>\n",
       "      <td>14.022928</td>\n",
       "      <td>12.652535</td>\n",
       "      <td>4.589902</td>\n",
       "      <td>4.339203</td>\n",
       "      <td>2.099701</td>\n",
       "      <td>1.347368</td>\n",
       "      <td>1.876216</td>\n",
       "      <td>1.994746</td>\n",
       "      <td>1.815644</td>\n",
       "      <td>2.049951</td>\n",
       "      <td>0.188785</td>\n",
       "      <td>Everton</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1567.656994</td>\n",
       "      <td>1549.801937</td>\n",
       "      <td>1.330970</td>\n",
       "      <td>1.232383</td>\n",
       "      <td>5.442022</td>\n",
       "      <td>4.320277</td>\n",
       "      <td>10.632374</td>\n",
       "      <td>11.395848</td>\n",
       "      <td>1.401492</td>\n",
       "      <td>1.318978</td>\n",
       "      <td>0.591241</td>\n",
       "      <td>0.501612</td>\n",
       "      <td>0.128647</td>\n",
       "      <td>0.097965</td>\n",
       "      <td>13.651956</td>\n",
       "      <td>10.228199</td>\n",
       "      <td>4.534917</td>\n",
       "      <td>3.846102</td>\n",
       "      <td>1.357584</td>\n",
       "      <td>1.231665</td>\n",
       "      <td>1.993966</td>\n",
       "      <td>1.884081</td>\n",
       "      <td>2.123252</td>\n",
       "      <td>1.754956</td>\n",
       "      <td>0.106011</td>\n",
       "      <td>1.592553</td>\n",
       "      <td>4.602562</td>\n",
       "      <td>1.562375</td>\n",
       "      <td>4.967551</td>\n",
       "      <td>1.928114</td>\n",
       "      <td>3.080280</td>\n",
       "      <td>1.689039</td>\n",
       "      <td>6.400569</td>\n",
       "      <td>1.677174</td>\n",
       "      <td>4.441914</td>\n",
       "      <td>draw</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>2018-08-26</td>\n",
       "      <td>4951</td>\n",
       "      <td>Watford</td>\n",
       "      <td>1819</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1520.411452</td>\n",
       "      <td>1546.461760</td>\n",
       "      <td>1.018660</td>\n",
       "      <td>1.607977</td>\n",
       "      <td>5.066188</td>\n",
       "      <td>4.833421</td>\n",
       "      <td>10.483965</td>\n",
       "      <td>11.992207</td>\n",
       "      <td>1.581523</td>\n",
       "      <td>1.106250</td>\n",
       "      <td>0.735976</td>\n",
       "      <td>0.447844</td>\n",
       "      <td>0.071242</td>\n",
       "      <td>0.079449</td>\n",
       "      <td>10.826491</td>\n",
       "      <td>11.602295</td>\n",
       "      <td>4.021974</td>\n",
       "      <td>3.862998</td>\n",
       "      <td>1.662156</td>\n",
       "      <td>1.751864</td>\n",
       "      <td>1.938889</td>\n",
       "      <td>1.939490</td>\n",
       "      <td>2.053532</td>\n",
       "      <td>1.915178</td>\n",
       "      <td>0.436705</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1546.461760</td>\n",
       "      <td>1520.411452</td>\n",
       "      <td>1.108738</td>\n",
       "      <td>1.462203</td>\n",
       "      <td>5.611883</td>\n",
       "      <td>5.300684</td>\n",
       "      <td>11.293843</td>\n",
       "      <td>11.171714</td>\n",
       "      <td>1.349860</td>\n",
       "      <td>1.350959</td>\n",
       "      <td>0.681212</td>\n",
       "      <td>0.518444</td>\n",
       "      <td>0.072246</td>\n",
       "      <td>0.041085</td>\n",
       "      <td>12.692089</td>\n",
       "      <td>11.836398</td>\n",
       "      <td>4.556892</td>\n",
       "      <td>4.137001</td>\n",
       "      <td>1.861655</td>\n",
       "      <td>1.849007</td>\n",
       "      <td>2.010493</td>\n",
       "      <td>1.870704</td>\n",
       "      <td>1.848792</td>\n",
       "      <td>2.020223</td>\n",
       "      <td>0.281209</td>\n",
       "      <td>1.700947</td>\n",
       "      <td>2.651476</td>\n",
       "      <td>2.323532</td>\n",
       "      <td>1.081644</td>\n",
       "      <td>2.363116</td>\n",
       "      <td>2.989988</td>\n",
       "      <td>0.933416</td>\n",
       "      <td>1.644591</td>\n",
       "      <td>2.010164</td>\n",
       "      <td>2.191385</td>\n",
       "      <td>home</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>2018-08-26</td>\n",
       "      <td>4952</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>1819</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1513.740462</td>\n",
       "      <td>1663.134224</td>\n",
       "      <td>1.263713</td>\n",
       "      <td>1.457554</td>\n",
       "      <td>5.663536</td>\n",
       "      <td>4.187155</td>\n",
       "      <td>10.328695</td>\n",
       "      <td>10.939110</td>\n",
       "      <td>1.239496</td>\n",
       "      <td>1.054580</td>\n",
       "      <td>0.586392</td>\n",
       "      <td>0.443609</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.091234</td>\n",
       "      <td>12.452771</td>\n",
       "      <td>11.747707</td>\n",
       "      <td>4.003907</td>\n",
       "      <td>3.858941</td>\n",
       "      <td>1.621902</td>\n",
       "      <td>1.362317</td>\n",
       "      <td>1.867457</td>\n",
       "      <td>2.006749</td>\n",
       "      <td>2.024455</td>\n",
       "      <td>1.911703</td>\n",
       "      <td>0.379764</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1663.134224</td>\n",
       "      <td>1513.740462</td>\n",
       "      <td>1.848987</td>\n",
       "      <td>0.860756</td>\n",
       "      <td>3.755354</td>\n",
       "      <td>5.849745</td>\n",
       "      <td>11.132337</td>\n",
       "      <td>9.514379</td>\n",
       "      <td>1.074810</td>\n",
       "      <td>1.771308</td>\n",
       "      <td>0.414233</td>\n",
       "      <td>0.893722</td>\n",
       "      <td>0.042799</td>\n",
       "      <td>0.054557</td>\n",
       "      <td>9.727137</td>\n",
       "      <td>16.066182</td>\n",
       "      <td>3.341093</td>\n",
       "      <td>5.717481</td>\n",
       "      <td>1.928424</td>\n",
       "      <td>1.130717</td>\n",
       "      <td>1.879666</td>\n",
       "      <td>1.984855</td>\n",
       "      <td>1.805033</td>\n",
       "      <td>2.053100</td>\n",
       "      <td>-0.926899</td>\n",
       "      <td>1.833687</td>\n",
       "      <td>10.622580</td>\n",
       "      <td>2.323532</td>\n",
       "      <td>12.338755</td>\n",
       "      <td>2.186764</td>\n",
       "      <td>12.897203</td>\n",
       "      <td>2.666904</td>\n",
       "      <td>11.734376</td>\n",
       "      <td>2.132119</td>\n",
       "      <td>11.813535</td>\n",
       "      <td>away</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>2018-08-26</td>\n",
       "      <td>4953</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>1819</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1405.922861</td>\n",
       "      <td>1523.094877</td>\n",
       "      <td>1.137916</td>\n",
       "      <td>1.434621</td>\n",
       "      <td>5.975406</td>\n",
       "      <td>5.069325</td>\n",
       "      <td>10.171646</td>\n",
       "      <td>9.963712</td>\n",
       "      <td>2.186921</td>\n",
       "      <td>1.087311</td>\n",
       "      <td>0.628756</td>\n",
       "      <td>0.350691</td>\n",
       "      <td>0.030692</td>\n",
       "      <td>0.043723</td>\n",
       "      <td>16.577464</td>\n",
       "      <td>11.759445</td>\n",
       "      <td>7.149427</td>\n",
       "      <td>4.548139</td>\n",
       "      <td>1.314872</td>\n",
       "      <td>1.393248</td>\n",
       "      <td>1.884552</td>\n",
       "      <td>1.985978</td>\n",
       "      <td>1.756776</td>\n",
       "      <td>2.128261</td>\n",
       "      <td>0.502253</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1523.094877</td>\n",
       "      <td>1405.922861</td>\n",
       "      <td>0.938616</td>\n",
       "      <td>1.525725</td>\n",
       "      <td>6.009157</td>\n",
       "      <td>4.388209</td>\n",
       "      <td>11.883636</td>\n",
       "      <td>9.503644</td>\n",
       "      <td>1.244818</td>\n",
       "      <td>0.939679</td>\n",
       "      <td>0.422908</td>\n",
       "      <td>0.382256</td>\n",
       "      <td>0.088614</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>14.509454</td>\n",
       "      <td>10.273809</td>\n",
       "      <td>4.536976</td>\n",
       "      <td>3.510299</td>\n",
       "      <td>1.211391</td>\n",
       "      <td>1.578136</td>\n",
       "      <td>1.965764</td>\n",
       "      <td>1.906055</td>\n",
       "      <td>2.282184</td>\n",
       "      <td>1.675649</td>\n",
       "      <td>0.234690</td>\n",
       "      <td>0.466927</td>\n",
       "      <td>1.784327</td>\n",
       "      <td>3.405176</td>\n",
       "      <td>1.862832</td>\n",
       "      <td>0.540813</td>\n",
       "      <td>1.975141</td>\n",
       "      <td>1.066761</td>\n",
       "      <td>2.622455</td>\n",
       "      <td>1.423612</td>\n",
       "      <td>1.915461</td>\n",
       "      <td>home</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>4954</td>\n",
       "      <td>Man United</td>\n",
       "      <td>1819</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1710.162262</td>\n",
       "      <td>1742.881762</td>\n",
       "      <td>1.869823</td>\n",
       "      <td>0.880053</td>\n",
       "      <td>4.477146</td>\n",
       "      <td>5.425172</td>\n",
       "      <td>11.618709</td>\n",
       "      <td>10.743441</td>\n",
       "      <td>0.850325</td>\n",
       "      <td>1.583027</td>\n",
       "      <td>0.436860</td>\n",
       "      <td>0.729685</td>\n",
       "      <td>0.039381</td>\n",
       "      <td>0.025416</td>\n",
       "      <td>10.877505</td>\n",
       "      <td>12.906563</td>\n",
       "      <td>3.568348</td>\n",
       "      <td>4.591495</td>\n",
       "      <td>1.739059</td>\n",
       "      <td>1.704108</td>\n",
       "      <td>1.871586</td>\n",
       "      <td>2.031787</td>\n",
       "      <td>1.900655</td>\n",
       "      <td>1.963478</td>\n",
       "      <td>-0.942445</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1742.881762</td>\n",
       "      <td>1710.162262</td>\n",
       "      <td>1.554950</td>\n",
       "      <td>1.234299</td>\n",
       "      <td>3.832376</td>\n",
       "      <td>6.310888</td>\n",
       "      <td>10.733193</td>\n",
       "      <td>10.073222</td>\n",
       "      <td>0.965620</td>\n",
       "      <td>2.104645</td>\n",
       "      <td>0.444596</td>\n",
       "      <td>0.795228</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.025266</td>\n",
       "      <td>9.997676</td>\n",
       "      <td>16.394215</td>\n",
       "      <td>3.393533</td>\n",
       "      <td>6.123974</td>\n",
       "      <td>1.913601</td>\n",
       "      <td>1.348745</td>\n",
       "      <td>1.947833</td>\n",
       "      <td>1.919607</td>\n",
       "      <td>1.629089</td>\n",
       "      <td>2.383593</td>\n",
       "      <td>-1.235630</td>\n",
       "      <td>11.406350</td>\n",
       "      <td>9.038365</td>\n",
       "      <td>10.295649</td>\n",
       "      <td>12.178511</td>\n",
       "      <td>8.229756</td>\n",
       "      <td>10.628142</td>\n",
       "      <td>13.690106</td>\n",
       "      <td>5.956085</td>\n",
       "      <td>10.399088</td>\n",
       "      <td>10.197460</td>\n",
       "      <td>away</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4896 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  gameId     HomeTeam season  f_homeWinPc38Home  \\\n",
       "20   2005-08-23      21   Birmingham   0506           0.394737   \n",
       "21   2005-08-23      22   Portsmouth   0506           0.447368   \n",
       "22   2005-08-23      23   Sunderland   0506           0.236842   \n",
       "23   2005-08-24      24      Arsenal   0506           0.736842   \n",
       "24   2005-08-24      25    Blackburn   0506           0.263158   \n",
       "...         ...     ...          ...    ...                ...   \n",
       "4949 2018-08-25    4950  Bournemouth   1819           0.447368   \n",
       "4950 2018-08-26    4951      Watford   1819           0.421053   \n",
       "4951 2018-08-26    4952    Newcastle   1819           0.394737   \n",
       "4952 2018-08-26    4953       Fulham   1819           0.289474   \n",
       "4953 2018-08-27    4954   Man United   1819           0.605263   \n",
       "\n",
       "      f_homeWinPc5Home  f_awayWinPc38Home  f_awayWinPc5Home  f_eloForHome  \\\n",
       "20                 0.4           0.263158               0.2   1478.687038   \n",
       "21                 0.4           0.263158               0.4   1405.968416   \n",
       "22                 0.0           0.236842               0.4   1277.888970   \n",
       "23                 1.0           0.236842               0.2   1729.086068   \n",
       "24                 0.6           0.263158               0.2   1496.457214   \n",
       "...                ...                ...               ...           ...   \n",
       "4949               0.6           0.157895               0.4   1549.801937   \n",
       "4950               0.4           0.289474               0.6   1520.411452   \n",
       "4951               0.6           0.605263               0.8   1513.740462   \n",
       "4952               0.2           0.210526               0.4   1405.922861   \n",
       "4953               0.8           0.526316               0.6   1710.162262   \n",
       "\n",
       "      f_eloAgainstHome  f_wtEloGoalsForHome  f_wtEloGoalsAgainstHome  \\\n",
       "20         1492.866048             1.061763                 1.260223   \n",
       "21         1489.229314             1.147101                 1.503051   \n",
       "22         1552.291880             0.650176                 1.543716   \n",
       "23         1481.943781             2.099593                 0.921523   \n",
       "24         1535.410612             1.248951                 1.308457   \n",
       "...                ...                  ...                      ...   \n",
       "4949       1567.656994             1.261521                 1.720533   \n",
       "4950       1546.461760             1.018660                 1.607977   \n",
       "4951       1663.134224             1.263713                 1.457554   \n",
       "4952       1523.094877             1.137916                 1.434621   \n",
       "4953       1742.881762             1.869823                 0.880053   \n",
       "\n",
       "      f_cornersAgainstHome  f_cornersForHome  f_freesAgainstHome  \\\n",
       "20                4.979592          7.530612           12.000000   \n",
       "21                2.510204          4.959184           21.979592   \n",
       "22                5.000000          5.000000           12.408163   \n",
       "23                3.000000          7.489796           17.000000   \n",
       "24                1.489796          7.020408           12.530612   \n",
       "...                    ...               ...                 ...   \n",
       "4949              5.380406          5.765467           11.482014   \n",
       "4950              5.066188          4.833421           10.483965   \n",
       "4951              5.663536          4.187155           10.328695   \n",
       "4952              5.975406          5.069325           10.171646   \n",
       "4953              4.477146          5.425172           11.618709   \n",
       "\n",
       "      f_freesForHome  f_goalsAgainstHome  f_goalsForHome  \\\n",
       "20          9.938776            1.020408        0.510204   \n",
       "21         16.061224            2.000000        0.510204   \n",
       "22         17.551020            1.979592        0.489796   \n",
       "23         18.061224            0.510204        0.979592   \n",
       "24         20.122449            1.979592        1.510204   \n",
       "...              ...                 ...             ...   \n",
       "4949        9.224256            1.591704        1.359998   \n",
       "4950       11.992207            1.581523        1.106250   \n",
       "4951       10.939110            1.239496        1.054580   \n",
       "4952        9.963712            2.186921        1.087311   \n",
       "4953       10.743441            0.850325        1.583027   \n",
       "\n",
       "      f_halfTimeGoalsAgainstHome  f_halfTimeGoalsForHome  f_redsAgainstHome  \\\n",
       "20                      0.510204                0.510204           0.000000   \n",
       "21                      1.000000                0.000000           0.000000   \n",
       "22                      1.000000                0.489796           0.489796   \n",
       "23                      0.000000                0.000000           0.489796   \n",
       "24                      0.000000                1.000000           0.000000   \n",
       "...                          ...                     ...                ...   \n",
       "4949                    0.704842                0.500421           0.023102   \n",
       "4950                    0.735976                0.447844           0.071242   \n",
       "4951                    0.586392                0.443609           0.005387   \n",
       "4952                    0.628756                0.350691           0.030692   \n",
       "4953                    0.436860                0.729685           0.039381   \n",
       "\n",
       "      f_redsForHome  f_shotsAgainstHome  f_shotsForHome  \\\n",
       "20         0.000000           11.938776        8.020408   \n",
       "21         0.000000            8.448980       10.489796   \n",
       "22         0.510204           14.510204        6.897959   \n",
       "23         0.000000            5.571429       11.938776   \n",
       "24         0.489796           10.448980       13.551020   \n",
       "...             ...                 ...             ...   \n",
       "4949       0.024295           14.022928       12.652535   \n",
       "4950       0.079449           10.826491       11.602295   \n",
       "4951       0.091234           12.452771       11.747707   \n",
       "4952       0.043723           16.577464       11.759445   \n",
       "4953       0.025416           10.877505       12.906563   \n",
       "\n",
       "      f_shotsOnTargetAgainstHome  f_shotsOnTargetForHome  \\\n",
       "20                      6.489796                2.979592   \n",
       "21                      3.959184                4.448980   \n",
       "22                      5.020408                3.918367   \n",
       "23                      3.551020                7.408163   \n",
       "24                      4.489796                7.040816   \n",
       "...                          ...                     ...   \n",
       "4949                    4.589902                4.339203   \n",
       "4950                    4.021974                3.862998   \n",
       "4951                    4.003907                3.858941   \n",
       "4952                    7.149427                4.548139   \n",
       "4953                    3.568348                4.591495   \n",
       "\n",
       "      f_yellowsAgainstHome  f_yellowsForHome  \\\n",
       "20                1.000000          2.510204   \n",
       "21                3.020408          1.530612   \n",
       "22                1.020408          2.510204   \n",
       "23                1.510204          1.530612   \n",
       "24                1.020408          1.510204   \n",
       "...                    ...               ...   \n",
       "4949              2.099701          1.347368   \n",
       "4950              1.662156          1.751864   \n",
       "4951              1.621902          1.362317   \n",
       "4952              1.314872          1.393248   \n",
       "4953              1.739059          1.704108   \n",
       "\n",
       "      f_avAsianHandicapOddsAgainstHome  f_avAsianHandicapOddsForHome  \\\n",
       "20                            1.909000                      1.945500   \n",
       "21                            1.896500                      1.969000   \n",
       "22                            1.852000                      1.991500   \n",
       "23                            1.945500                      1.909000   \n",
       "24                            1.803500                      2.056500   \n",
       "...                                ...                           ...   \n",
       "4949                          1.876216                      1.994746   \n",
       "4950                          1.938889                      1.939490   \n",
       "4951                          1.867457                      2.006749   \n",
       "4952                          1.884552                      1.985978   \n",
       "4953                          1.871586                      2.031787   \n",
       "\n",
       "      f_avgreaterthan2.5Home  f_avlessthan2.5Home  f_sizeOfHandicapHome  \\\n",
       "20                  2.051000             1.673500             -0.137500   \n",
       "21                  2.004000             1.700500              0.250000   \n",
       "22                  1.853500             1.850000              0.712500   \n",
       "23                  1.876000             1.828500             -0.287500   \n",
       "24                  2.014500             1.693500             -0.275000   \n",
       "...                      ...                  ...                   ...   \n",
       "4949                1.815644             2.049951              0.188785   \n",
       "4950                2.053532             1.915178              0.436705   \n",
       "4951                2.024455             1.911703              0.379764   \n",
       "4952                1.756776             2.128261              0.502253   \n",
       "4953                1.900655             1.963478             -0.942445   \n",
       "\n",
       "            AwayTeam  f_homeWinPc38Away  f_homeWinPc5Away  f_awayWinPc38Away  \\\n",
       "20     Middlesbrough           0.394737               0.4           0.263158   \n",
       "21       Aston Villa           0.447368               0.4           0.263158   \n",
       "22          Man City           0.236842               0.0           0.236842   \n",
       "23            Fulham           0.736842               1.0           0.236842   \n",
       "24         Tottenham           0.263158               0.6           0.263158   \n",
       "...              ...                ...               ...                ...   \n",
       "4949         Everton           0.447368               0.6           0.157895   \n",
       "4950  Crystal Palace           0.421053               0.4           0.289474   \n",
       "4951         Chelsea           0.394737               0.6           0.605263   \n",
       "4952         Burnley           0.289474               0.2           0.210526   \n",
       "4953       Tottenham           0.605263               0.8           0.526316   \n",
       "\n",
       "      f_awayWinPc5Away  f_eloForAway  f_eloAgainstAway  f_wtEloGoalsForAway  \\\n",
       "20                 0.2   1492.866048       1478.687038             1.129940   \n",
       "21                 0.4   1489.229314       1405.968416             1.175160   \n",
       "22                 0.4   1552.291880       1277.888970             1.288750   \n",
       "23                 0.2   1481.943781       1729.086068             1.170928   \n",
       "24                 0.2   1535.410612       1496.457214             1.274824   \n",
       "...                ...           ...               ...                  ...   \n",
       "4949               0.4   1567.656994       1549.801937             1.330970   \n",
       "4950               0.6   1546.461760       1520.411452             1.108738   \n",
       "4951               0.8   1663.134224       1513.740462             1.848987   \n",
       "4952               0.4   1523.094877       1405.922861             0.938616   \n",
       "4953               0.6   1742.881762       1710.162262             1.554950   \n",
       "\n",
       "      f_wtEloGoalsAgainstAway  f_cornersAgainstAway  f_cornersForAway  \\\n",
       "20                   1.279873              2.551020          5.510204   \n",
       "21                   1.263229              9.530612          7.000000   \n",
       "22                   1.287367              7.530612          3.510204   \n",
       "23                   1.323440              7.020408          3.448980   \n",
       "24                   1.393005              6.489796          3.530612   \n",
       "...                       ...                   ...               ...   \n",
       "4949                 1.232383              5.442022          4.320277   \n",
       "4950                 1.462203              5.611883          5.300684   \n",
       "4951                 0.860756              3.755354          5.849745   \n",
       "4952                 1.525725              6.009157          4.388209   \n",
       "4953                 1.234299              3.832376          6.310888   \n",
       "\n",
       "      f_freesAgainstAway  f_freesForAway  f_goalsAgainstAway  f_goalsForAway  \\\n",
       "20             13.551020       13.428571            1.020408        0.000000   \n",
       "21             14.469388       17.571429            1.489796        0.979592   \n",
       "22              8.959184       12.489796            0.510204        1.020408   \n",
       "23             19.632653       13.020408            1.020408        0.510204   \n",
       "24             11.469388       19.428571            0.000000        2.000000   \n",
       "...                  ...             ...                 ...             ...   \n",
       "4949           10.632374       11.395848            1.401492        1.318978   \n",
       "4950           11.293843       11.171714            1.349860        1.350959   \n",
       "4951           11.132337        9.514379            1.074810        1.771308   \n",
       "4952           11.883636        9.503644            1.244818        0.939679   \n",
       "4953           10.733193       10.073222            0.965620        2.104645   \n",
       "\n",
       "      f_halfTimeGoalsAgainstAway  f_halfTimeGoalsForAway  f_redsAgainstAway  \\\n",
       "20                      0.000000                0.000000           0.000000   \n",
       "21                      0.979592                0.979592           0.000000   \n",
       "22                      0.510204                0.510204           0.000000   \n",
       "23                      0.510204                0.000000           0.000000   \n",
       "24                      0.000000                0.489796           0.000000   \n",
       "...                          ...                     ...                ...   \n",
       "4949                    0.591241                0.501612           0.128647   \n",
       "4950                    0.681212                0.518444           0.072246   \n",
       "4951                    0.414233                0.893722           0.042799   \n",
       "4952                    0.422908                0.382256           0.088614   \n",
       "4953                    0.444596                0.795228           0.020651   \n",
       "\n",
       "      f_redsForAway  f_shotsAgainstAway  f_shotsForAway  \\\n",
       "20         0.489796           17.020408        8.081633   \n",
       "21         0.000000           15.551020        3.000000   \n",
       "22         0.000000           10.959184       11.938776   \n",
       "23         0.000000           11.591837       11.428571   \n",
       "24         0.000000           11.510204       14.571429   \n",
       "...             ...                 ...             ...   \n",
       "4949       0.097965           13.651956       10.228199   \n",
       "4950       0.041085           12.692089       11.836398   \n",
       "4951       0.054557            9.727137       16.066182   \n",
       "4952       0.012340           14.509454       10.273809   \n",
       "4953       0.025266            9.997676       16.394215   \n",
       "\n",
       "      f_shotsOnTargetAgainstAway  f_shotsOnTargetForAway  \\\n",
       "20                      7.510204                2.510204   \n",
       "21                      9.061224                2.510204   \n",
       "22                      2.489796                6.979592   \n",
       "23                      6.551020                5.469388   \n",
       "24                      4.959184                7.020408   \n",
       "...                          ...                     ...   \n",
       "4949                    4.534917                3.846102   \n",
       "4950                    4.556892                4.137001   \n",
       "4951                    3.341093                5.717481   \n",
       "4952                    4.536976                3.510299   \n",
       "4953                    3.393533                6.123974   \n",
       "\n",
       "      f_yellowsAgainstAway  f_yellowsForAway  \\\n",
       "20                3.000000          1.489796   \n",
       "21                2.000000          0.510204   \n",
       "22                3.000000          1.489796   \n",
       "23                2.000000          1.510204   \n",
       "24                0.510204          2.510204   \n",
       "...                    ...               ...   \n",
       "4949              1.357584          1.231665   \n",
       "4950              1.861655          1.849007   \n",
       "4951              1.928424          1.130717   \n",
       "4952              1.211391          1.578136   \n",
       "4953              1.913601          1.348745   \n",
       "\n",
       "      f_avAsianHandicapOddsAgainstAway  f_avAsianHandicapOddsForAway  \\\n",
       "20                            1.939500                      1.909500   \n",
       "21                            1.856500                      1.977000   \n",
       "22                            1.815000                      2.039500   \n",
       "23                            2.061000                      1.799000   \n",
       "24                            1.914000                      1.935000   \n",
       "...                                ...                           ...   \n",
       "4949                          1.993966                      1.884081   \n",
       "4950                          2.010493                      1.870704   \n",
       "4951                          1.879666                      1.984855   \n",
       "4952                          1.965764                      1.906055   \n",
       "4953                          1.947833                      1.919607   \n",
       "\n",
       "      f_avgreaterthan2.5Away  f_avlessthan2.5Away  f_sizeOfHandicapAway  \\\n",
       "20                  2.003500             1.715500              0.387500   \n",
       "21                  1.850500             1.848500              0.712500   \n",
       "22                  2.006000             1.709500             -0.200000   \n",
       "23                  2.023500             1.684500              0.275000   \n",
       "24                  1.976500             1.733500             -0.387500   \n",
       "...                      ...                  ...                   ...   \n",
       "4949                2.123252             1.754956              0.106011   \n",
       "4950                1.848792             2.020223              0.281209   \n",
       "4951                1.805033             2.053100             -0.926899   \n",
       "4952                2.282184             1.675649              0.234690   \n",
       "4953                1.629089             2.383593             -1.235630   \n",
       "\n",
       "      f_attMktH%  f_attMktA%  f_midMktH%  f_midMktA%  f_defMktH%  f_defMktA%  \\\n",
       "20      5.132983    5.260851    3.341048    4.289788    3.502318    4.168935   \n",
       "21      3.738614    3.878659    4.494368    4.954673    2.884262    4.065926   \n",
       "22      0.706318    3.750792    1.476812    1.070209    2.634096    4.455890   \n",
       "23     10.807882    0.785474    8.064289    4.161925    9.116327    3.583254   \n",
       "24      1.583126    5.553120    3.477861    6.881561    4.010007    5.537488   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "4949    1.592553    4.602562    1.562375    4.967551    1.928114    3.080280   \n",
       "4950    1.700947    2.651476    2.323532    1.081644    2.363116    2.989988   \n",
       "4951    1.833687   10.622580    2.323532   12.338755    2.186764   12.897203   \n",
       "4952    0.466927    1.784327    3.405176    1.862832    0.540813    1.975141   \n",
       "4953   11.406350    9.038365   10.295649   12.178511    8.229756   10.628142   \n",
       "\n",
       "      f_gkMktH%  f_gkMktA%  f_totalMktH%  f_totalMktA% result  f_awayOdds  \\\n",
       "20     2.332815   3.216457      3.934396      4.522205   away        2.75   \n",
       "21     3.746642   5.372543      3.743410      4.365456   draw        2.75   \n",
       "22     0.777605   4.913050      1.499427      3.151477   away        2.50   \n",
       "23     3.661813   5.337198      9.031622      2.924604   home       13.00   \n",
       "24     2.297469   5.973420      2.916354      6.001831   draw        2.60   \n",
       "...         ...        ...           ...           ...    ...         ...   \n",
       "4949   1.689039   6.400569      1.677174      4.441914   draw        2.75   \n",
       "4950   0.933416   1.644591      2.010164      2.191385   home        3.00   \n",
       "4951   2.666904  11.734376      2.132119     11.813535   away        1.66   \n",
       "4952   1.066761   2.622455      1.423612      1.915461   home        4.33   \n",
       "4953  13.690106   5.956085     10.399088     10.197460   away        2.90   \n",
       "\n",
       "      f_drawOdds  f_homeOdds  \n",
       "20          3.20        2.50  \n",
       "21          3.20        2.50  \n",
       "22          3.20        2.75  \n",
       "23          5.50        1.22  \n",
       "24          3.20        2.62  \n",
       "...          ...         ...  \n",
       "4949        3.60        2.62  \n",
       "4950        3.25        2.60  \n",
       "4951        4.00        5.75  \n",
       "4952        3.40        2.00  \n",
       "4953        3.30        2.62  \n",
       "\n",
       "[4896 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3b168",
   "metadata": {},
   "source": [
    "To start our modelling process, we need to make a training set, a test set and a holdout set. <br>\n",
    "<br>\n",
    "As we are using cross validation, we will make our training set all of the seasons up until 2017/18, and we will use the 2017/18 season as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73420996",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [col for col in features.columns if col.startswith(\"f_\")]\n",
    "\n",
    "le = LabelEncoder() # initiate a label encoder to transform the labels 'away', 'draw', 'home' to 0,1,2\n",
    "\n",
    "# Grab all seasons except for 2017/18 to use cross validation with\n",
    "all_x = features.loc[features.season != '17/18', ['gameId'] + feature_list]\n",
    "all_y = features.loc[features.season != '17/18', 'result']\n",
    "all_y = le.fit_transform(all_y)\n",
    "\n",
    "train_x = features.loc[~features.season.isin(['16/17', '17/18']), ['gameId'] + feature_list]\n",
    "train_y = le.transform(features.loc[~features.season.isin(['16/17', '17/18']), 'result'])\n",
    "\n",
    "holdout_x = features.loc[features.season == '16/17', ['gameId'] + feature_list]\n",
    "holdout_y = le.transform(features.loc[features.season == '16/17', 'result'])\n",
    "\n",
    "test_x = features.loc[features.season == '17/18', ['gameId'] + feature_list]\n",
    "test_y = le.transform(features.loc[features.season == '17/18', 'result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b9615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of standard classifiers\n",
    "classifiers = [\n",
    "\n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "#     xgb.XGBClassifier()    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f74a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_algorithms(classifier_list, X, y):\n",
    "    # This function is adapted from https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    cv_results = [cross_val_score(classifier, X, y, scoring = \"neg_log_loss\", cv = kfold) for classifier in classifier_list]\n",
    "    cv_means = [cv_result.mean() * -1 for cv_result in cv_results]\n",
    "    cv_std = [cv_result.std() for cv_result in cv_results]\n",
    "    algorithm_names = [alg.__class__.__name__ for alg in classifiers]\n",
    "    \n",
    "    # create a dataframe of all the CV results\n",
    "    cv_results = pd.DataFrame({\n",
    "        \"Mean Log Loss\": cv_means,\n",
    "        \"Log Loss Std\": cv_std,\n",
    "        \"Algorithm\": algorithm_names\n",
    "    }).sort_values(by=\"Mean Log Loss\")\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ad5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_results = find_best_algorithms(classifiers, all_x, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a4445c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Log Loss</th>\n",
       "      <th>Log Loss Std</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.965229</td>\n",
       "      <td>0.011466</td>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.996645</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.015659</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.015792</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>BernoulliNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.043758</td>\n",
       "      <td>0.097858</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.081107</td>\n",
       "      <td>0.102342</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.092277</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.218542</td>\n",
       "      <td>0.223842</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.394628</td>\n",
       "      <td>4.239353</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.203299</td>\n",
       "      <td>2.484321</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean Log Loss  Log Loss Std                      Algorithm\n",
       "0        0.965229      0.011466           LogisticRegressionCV\n",
       "7        0.996645      0.019931           ExtraTreesClassifier\n",
       "9        0.999708      0.015659         RandomForestClassifier\n",
       "1        1.015792      0.010107                    BernoulliNB\n",
       "3        1.043758      0.097858     LinearDiscriminantAnalysis\n",
       "8        1.081107      0.102342     GradientBoostingClassifier\n",
       "5        1.092277      0.005261             AdaBoostClassifier\n",
       "10       1.098612      0.000000      GaussianProcessClassifier\n",
       "6        2.218542      0.223842              BaggingClassifier\n",
       "4        5.394628      4.239353  QuadraticDiscriminantAnalysis\n",
       "2        6.203299      2.484321                     GaussianNB"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d99d668",
   "metadata": {},
   "source": [
    "We can see that the LogisticRegression seems to perform the best out of all the algorithms, and some algorithms have a very high log loss. <br>\n",
    "This is most likely due to overfitting. It would definitely be useful to condense our features down to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e37c416",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aec857",
   "metadata": {},
   "source": [
    "Since it was best performing, we will use logistic regression. I will first try to fine tune a logistic regression model with cross validation, using grid search. \n",
    "* Grid search essentially tries out each combination of values and finds the model with the lowest error metric, which in our case is log loss.\n",
    "* 'C' in logistic regression determines the amount of regularisation.\n",
    "* Lower values increase regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a7c994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best log loss: 0.9638207733217344\n"
     ]
    }
   ],
   "source": [
    "# Define our parameters to run a grid search over\n",
    "lr_grid = {\n",
    "    \"C\": [0.0001, 0.01, 0.05, 0.2, 1],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "gs = GridSearchCV(LogisticRegression(), param_grid=lr_grid, cv=kfold, scoring='neg_log_loss')\n",
    "gs.fit(all_x, all_y)\n",
    "print(\"Best log loss: {}\".format(gs.best_score_ *-1))\n",
    "best_lr_params = gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3863862",
   "metadata": {},
   "source": [
    "## Defining a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d40de",
   "metadata": {},
   "source": [
    "It is necessary at this point to define a baseline, as we don't really know if the log loss is good or bad. <br>\n",
    "<br>\n",
    "Randomly assigning a 1/3 chance to each selection yields a log loss of log(3) = 1.09."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "119b72ae",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5fd90313",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f129b4b",
   "metadata": {},
   "source": [
    "However, we are most interested in how the model performs relative to the odds. \n",
    "<br><br>\n",
    "Important to find the log loss of the odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b99e2bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9580387769719025"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the log loss of the odds\n",
    "log_loss(all_y, 1 / all_x[['f_awayOdds', 'f_drawOdds', 'f_homeOdds']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd697dac",
   "metadata": {},
   "source": [
    "Good news as this algorithm almost beats the bookies in terms of log loss - Goal to try beat this result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d691e2a",
   "metadata": {},
   "source": [
    "## Analysing the Errors Made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71033aa0",
   "metadata": {},
   "source": [
    "Important to analyse the type of errors that have been made.\n",
    "<br>\n",
    "To do this, we will look at the confusion matrix produced when we predict our holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a988a94",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 72)) while a minimum of 1 is required by LogisticRegression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_lr_params) \u001b[38;5;66;03m# Instantiate the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m lr\u001b[38;5;241m.\u001b[39mfit(train_x, train_y) \u001b[38;5;66;03m# Fit our model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m lr_predict \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(holdout_x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:969\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 969\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    972\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    973\u001b[0m         )\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    976\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 72)) while a minimum of 1 is required by LogisticRegression."
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(**best_lr_params) # Instantiate the model\n",
    "lr.fit(train_x, train_y) # Fit our model\n",
    "lr_predict = lr.predict(holdout_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87230282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a confusion matrix\n",
    "c_matrix = (pd.DataFrame(confusion_matrix(holdout_y, lr_predict), columns=le.classes_, index=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ad065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c379e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
